(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{249:function(e,t,a){"use strict";var n=a(94);a.n(n).a},266:function(e,t,a){"use strict";a.r(t);a(249);var n=a(0),i=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"contents"}},[e._v("Contents")]),e._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#projects-undergoing"}},[e._v("Projects Undergoing")]),a("ul",[a("li",[a("a",{attrs:{href:"#segmentation-only-uses-sparse-annotations-unified-weakly-and-semi-supervised-segmentation-in-medical-image"}},[e._v("Segmentation Only Uses Sparse Annotations: Unified Weakly and Semi-Supervised Segmentation in Medical Image")])]),a("li",[a("a",{attrs:{href:"#carotid-plaques-segmentation-and-stenosis-degree-classification"}},[e._v("Carotid Plaques Segmentation and Stenosis Degree Classification")])])])]),a("li",[a("a",{attrs:{href:"#publications"}},[e._v("Publications")]),a("ul",[a("li",[a("a",{attrs:{href:"#fully-test-time-adaptation-for-image-segmentation"}},[e._v("Fully Test-time Adaptation for Image Segmentation")])]),a("li",[a("a",{attrs:{href:"#knowledge-distillation-from-multi-modal-to-mono-modal-segmentation-networks"}},[e._v("Knowledge Distillation from Multi-modal to Mono-modal Segmentation Networks")])])])])])]),a("p"),e._v(" "),a("h2",{attrs:{id:"projects-undergoing"}},[e._v("Projects Undergoing")]),e._v(" "),a("ProjectCard",{attrs:{image:"/projects/mia2021.pdf"}},[a("p",[e._v("üßëüèª‚Äçüíª üü©üü©üü©üü©‚¨úÔ∏è")]),e._v(" "),a("h3",{attrs:{id:"segmentation-only-uses-sparse-annotations-unified-weakly-and-semi-supervised-segmentation-in-medical-image"}},[e._v("Segmentation Only Uses Sparse Annotations: Unified Weakly and Semi-Supervised Segmentation in Medical Image")]),e._v(" "),a("p",[e._v("(A joint work with The Sixth Affiliated Hospital of Sun Yat-sen University. The paper is submitted to Medical Image Analysisü§û.)")]),e._v(" "),a("p",[a("strong",[e._v("Abstract")]),e._v(" Since segmentation labeling is usually time-consuming and annotating medical images requires professional expertise. It is laborious to obtain a large-scale, high-quality annotated segmentation dataset of medical images. We propose a novel weakly- and semi-supervised framework named SOUSA, aiming at learning from a small set of sparse annotated data and a large amount of unlabeled data. The proposed framework contains the teacher model and student model. The student model is weakly supervised by scribbles and a Geodesic distance map derived from scribble and the input image. Meanwhile, a large amount of unlabeled data with different perturbations are fed to both student and teacher models, and the consistency of their output predictions is imposed by Mean Square Error (MSE) loss and a carefully designed Multi-angle Projection Reconstruction (MPR) loss. Extensive experiments are conducted to demonstrate the robustness and generalization ability of our proposed method. Results show that our method outperforms weakly- and semi-supervised SOTA methods on multiple datasets. Furthermore, our method achieves a competitive or higher performance than some fully supervised methods when the size of the dataset is limited.")])]),e._v(" "),a("ProjectCard",[a("p",[e._v("üßëüèª‚Äçüíª üü©üü©üü©‚¨úÔ∏è‚¨úÔ∏è")]),e._v(" "),a("h3",{attrs:{id:"carotid-plaques-segmentation-and-stenosis-degree-classification"}},[e._v("Carotid Plaques Segmentation and Stenosis Degree Classification")])]),e._v(" "),a("h2",{attrs:{id:"publications"}},[e._v("Publications")]),e._v(" "),a("ProjectCard",{attrs:{image:"/projects/miccai2021.png"}},[a("p",[e._v("["),a("a",{attrs:{href:""}},[e._v("PDF")]),e._v("] ["),a("a",{attrs:{href:""}},[e._v("arXiv")]),e._v("] ["),a("a",{attrs:{href:"https://cdn.filestackcontent.com/R2AxCq6NTx6rw0gh4OZ1",target:"_blank",rel:"noopener noreferrer"}},[e._v("Video"),a("OutboundLink")],1),e._v("]")]),e._v(" "),a("h3",{attrs:{id:"fully-test-time-adaptation-for-image-segmentation"}},[e._v("Fully Test-time Adaptation for Image Segmentation")]),e._v(" "),a("p",[a("strong",[e._v("M Hu")]),e._v(" , T Song, Y Gu, X Luo, J Chen, Y Chen, Y Zhang, S Zhang")]),e._v(" "),a("p",[e._v("International Conference on Medical Image Computing & Computer Assisted Intervention (MICCAI 2021)")]),e._v(" "),a("p",[a("strong",[e._v("Abstract")]),e._v(" When adopting a model from the source domain to the target domain, its performance usually degrades due to the domain shift problem. In clinical practice, the source data usually cannot be accessed during adaptation for privacy policy and the label for the target domain is in shortage because of the high cost of professional labeling. Therefore, it is worth considering how to eÔ¨Äiciently adopt a pretrained model with only unlabeled data from the target domain. In this paper, we propose a novel fully test-time unsupervised adaptation method for image segmentation based on Regional Nuclear-norm (RN) and Contour Regularization (CR). The RN loss is specially designed for segmentation tasks to eÔ¨Äiciently improve discriminability and diversity of prediction. The CR loss constrains the continuity and connectivity to enhance the relevance between pixels and their neighbors. Instead of retraining all pa- rameters, we modify only the parameters in batch normalization layers with only a few epochs. We demonstrate the effectiveness and eÔ¨Äiciency of the proposed method in the pancreas and liver segmentation dataset from the Medical Segmentation Decathlon and CHAOS challenge.")])]),e._v(" "),a("ProjectCard",{attrs:{image:"/projects/miccai2020.jpg"}},[a("p",[e._v("["),a("a",{attrs:{href:"https://link.springer.com/chapter/10.1007/978-3-030-59710-8_75",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),a("OutboundLink")],1),e._v("] ["),a("a",{attrs:{href:"https://arxiv.org/pdf/2106.09564.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),a("OutboundLink")],1),e._v("]")]),e._v(" "),a("h3",{attrs:{id:"knowledge-distillation-from-multi-modal-to-mono-modal-segmentation-networks"}},[e._v("Knowledge Distillation from Multi-modal to Mono-modal Segmentation Networks")]),e._v(" "),a("p",[a("strong",[e._v("M Hu")]),e._v(", M Maillard, Y Zhang, T Ciceri, G La Barbera, I Bloch, P Gori")]),e._v(" "),a("p",[e._v("International Conference on Medical Image Computing & Computer Assisted Intervention (MICCAI 2020)")]),e._v(" "),a("p",[a("strong",[e._v("Abstract")]),e._v(" The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher‚Äôs inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy.")])])],1)}),[],!1,null,null,null);t.default=i.exports},94:function(e,t,a){}}]);