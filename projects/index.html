<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Contents | Hu Minhao</title>
    <meta name="description" content="Personal website">
    <link rel="icon" href="/profile.jpg">
    
    <link rel="preload" href="/assets/css/0.styles.6b5448c1.css" as="style"><link rel="preload" href="/assets/js/app.660be4f6.js" as="script"><link rel="preload" href="/assets/js/2.a151d002.js" as="script"><link rel="preload" href="/assets/js/9.4e254ed1.js" as="script"><link rel="preload" href="/assets/js/5.5cd0f01f.js" as="script"><link rel="prefetch" href="/assets/js/10.33e880a9.js"><link rel="prefetch" href="/assets/js/11.3bd19d36.js"><link rel="prefetch" href="/assets/js/12.caae3fee.js"><link rel="prefetch" href="/assets/js/3.7d1cc7b7.js"><link rel="prefetch" href="/assets/js/4.a00e457c.js"><link rel="prefetch" href="/assets/js/6.71c2e8ff.js"><link rel="prefetch" href="/assets/js/7.ab1e0987.js"><link rel="prefetch" href="/assets/js/8.3c59bb8f.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6b5448c1.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar projects-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Hu Minhao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/about/" class="nav-link">About</a></div><div class="nav-item"><a href="/projects/" class="nav-link router-link-exact-active router-link-active">Projects</a></div><div class="nav-item"><a href="https://github.com/LoicHmh" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/about/" class="nav-link">About</a></div><div class="nav-item"><a href="/projects/" class="nav-link router-link-exact-active router-link-active">Projects</a></div><div class="nav-item"><a href="https://github.com/LoicHmh" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="contents">Contents</h2> <p></p><div class="table-of-contents"><ul><li><a href="#contents">Contents</a></li><li><a href="#projects-undergoing">Projects Undergoing</a><ul><li><a href="#segmentation-only-uses-sparse-annotations-unified-weakly-and-semi-supervised-segmentation-in-medical-image">Segmentation Only Uses Sparse Annotations: Unified Weakly and Semi-Supervised Segmentation in Medical Image</a></li><li><a href="#carotid-plaques-segmentation-and-stenosis-degree-classification">Carotid Plaques Segmentation and Stenosis Degree Classification</a></li></ul></li><li><a href="#publications">Publications</a><ul><li><a href="#fully-test-time-adaptation-for-image-segmentation">Fully Test-time Adaptation for Image Segmentation</a></li><li><a href="#knowledge-distillation-from-multi-modal-to-mono-modal-segmentation-networks">Knowledge Distillation from Multi-modal to Mono-modal Segmentation Networks</a></li></ul></li></ul></div><p></p> <h2 id="projects-undergoing">Projects Undergoing</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/mia2021.pdf" alt></div> <div class="card-content"><p>🧑🏻‍💻 🟩🟩🟩🟩⬜️</p> <h3 id="segmentation-only-uses-sparse-annotations-unified-weakly-and-semi-supervised-segmentation-in-medical-image">Segmentation Only Uses Sparse Annotations: Unified Weakly and Semi-Supervised Segmentation in Medical Image</h3> <p>(A joint work with The Sixth Affiliated Hospital of Sun Yat-sen University. The paper is submitted to Medical Image Analysis🤞.)</p> <p><strong>Abstract</strong> Since segmentation labeling is usually time-consuming and annotating medical images requires professional expertise. It is laborious to obtain a large-scale, high-quality annotated segmentation dataset of medical images. We propose a novel weakly- and semi-supervised framework named SOUSA, aiming at learning from a small set of sparse annotated data and a large amount of unlabeled data. The proposed framework contains the teacher model and student model. The student model is weakly supervised by scribbles and a Geodesic distance map derived from scribble and the input image. Meanwhile, a large amount of unlabeled data with different perturbations are fed to both student and teacher models, and the consistency of their output predictions is imposed by Mean Square Error (MSE) loss and a carefully designed Multi-angle Projection Reconstruction (MPR) loss. Extensive experiments are conducted to demonstrate the robustness and generalization ability of our proposed method. Results show that our method outperforms weakly- and semi-supervised SOTA methods on multiple datasets. Furthermore, our method achieves a competitive or higher performance than some fully supervised methods when the size of the dataset is limited.</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p>🧑🏻‍💻 🟩🟩🟩⬜️⬜️</p> <h3 id="carotid-plaques-segmentation-and-stenosis-degree-classification">Carotid Plaques Segmentation and Stenosis Degree Classification</h3> <p>Internal Carotid Artery plaques is an significant public health problem which is highly related to ischemic stroke. In this project, we aim to segment the carotid plaques from CTA images. Then based on the segmentation results, we provide a new method to estimate the stenosis degree for each plaque area.</p></div></div> <h2 id="publications">Publications</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/miccai2021.png" alt></div> <div class="card-content"><p>[<a href="https://link.springer.com/chapter/10.1007/978-3-030-87199-4_24" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://cdn.filestackcontent.com/R2AxCq6NTx6rw0gh4OZ1" target="_blank" rel="noopener noreferrer">Video<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p> <h3 id="fully-test-time-adaptation-for-image-segmentation">Fully Test-time Adaptation for Image Segmentation</h3> <p><strong>M Hu</strong> , T Song, Y Gu, X Luo, J Chen, Y Chen, Y Zhang, S Zhang</p> <p>International Conference on Medical Image Computing &amp; Computer Assisted Intervention (MICCAI 2021)</p> <p><strong>Abstract</strong> When adopting a model from the source domain to the target domain, its performance usually degrades due to the domain shift problem. In clinical practice, the source data usually cannot be accessed during adaptation for privacy policy and the label for the target domain is in shortage because of the high cost of professional labeling. Therefore, it is worth considering how to eﬀiciently adopt a pretrained model with only unlabeled data from the target domain. In this paper, we propose a novel fully test-time unsupervised adaptation method for image segmentation based on Regional Nuclear-norm (RN) and Contour Regularization (CR). The RN loss is specially designed for segmentation tasks to eﬀiciently improve discriminability and diversity of prediction. The CR loss constrains the continuity and connectivity to enhance the relevance between pixels and their neighbors. Instead of retraining all pa- rameters, we modify only the parameters in batch normalization layers with only a few epochs. We demonstrate the effectiveness and eﬀiciency of the proposed method in the pancreas and liver segmentation dataset from the Medical Segmentation Decathlon and CHAOS challenge.</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/miccai2020.jpg" alt></div> <div class="card-content"><p>[<a href="https://link.springer.com/chapter/10.1007/978-3-030-59710-8_75" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://arxiv.org/pdf/2106.09564.pdf" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p> <h3 id="knowledge-distillation-from-multi-modal-to-mono-modal-segmentation-networks">Knowledge Distillation from Multi-modal to Mono-modal Segmentation Networks</h3> <p><strong>M Hu</strong>, M Maillard, Y Zhang, T Ciceri, G La Barbera, I Bloch, P Gori</p> <p>International Conference on Medical Image Computing &amp; Computer Assisted Intervention (MICCAI 2020)</p> <p><strong>Abstract</strong> The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher’s inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy.</p></div></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.660be4f6.js" defer></script><script src="/assets/js/2.a151d002.js" defer></script><script src="/assets/js/9.4e254ed1.js" defer></script><script src="/assets/js/5.5cd0f01f.js" defer></script>
  </body>
</html>
